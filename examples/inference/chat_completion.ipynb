{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import taskingai\n",
    "# Load TaskingAI API Key from environment variable"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:03:32.009173Z",
     "start_time": "2023-11-30T11:03:30.470410Z"
    }
   },
   "id": "1a6bfd1682fcb23f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TaskingAI Model Inference: Chat Completion"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "657463bd357a3c3"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from taskingai.inference import *\n",
    "import json\n",
    "# choose an available chat_completion model from your project\n",
    "model_id = \"Gk1145Bl\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:03:35.629715Z",
     "start_time": "2023-11-30T11:03:35.602754Z"
    }
   },
   "id": "49abde692940b09e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "ChatCompletion(object='ChatCompletion', finish_reason=<ChatCompletionFinishReason.stop: 'stop'>, message=ChatCompletionAssistantMessage(content='Hello! How can I assist you today?', role=<ChatCompletionRole.assistant: 'assistant'>, function_call=None), created_timestamp=1701342218014)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normal \n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a professional assistant.\"),\n",
    "        UserMessage(\"Hi\"),\n",
    "    ]\n",
    ")\n",
    "chat_completion_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:03:38.108157Z",
     "start_time": "2023-11-30T11:03:36.349445Z"
    }
   },
   "id": "43dcc632665f0de4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "ChatCompletion(object='ChatCompletion', finish_reason=<ChatCompletionFinishReason.stop: 'stop'>, message=ChatCompletionAssistantMessage(content=\"Of course! How about this one: Why don't skeletons fight each other? They don't have the guts!\", role=<ChatCompletionRole.assistant: 'assistant'>, function_call=None), created_timestamp=1701342220370)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi round chat completion\n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a professional assistant.\"),\n",
    "        UserMessage(\"Hi\"),\n",
    "        AssistantMessage(\"Hello! How can I assist you today?\"),\n",
    "        UserMessage(\"Can you tell me a joke?\"),\n",
    "        AssistantMessage(\"Sure, here is a joke for you: Why don't scientists trust atoms? Because they make up everything!\"),\n",
    "        UserMessage(\"That's funny. Can you tell me another one?\"),\n",
    "    ]\n",
    ")\n",
    "chat_completion_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:03:40.460984Z",
     "start_time": "2023-11-30T11:03:39.092991Z"
    }
   },
   "id": "e8933bc07f4b3228"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "ChatCompletion(object='ChatCompletion', finish_reason=<ChatCompletionFinishReason.length: 'length'>, message=ChatCompletionAssistantMessage(content=\"Of course! Here's\", role=<ChatCompletionRole.assistant: 'assistant'>, function_call=None), created_timestamp=1701342221823)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config max tokens\n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a professional assistant.\"),\n",
    "        UserMessage(\"Hi\"),\n",
    "        AssistantMessage(\"Hello! How can I assist you today?\"),\n",
    "        UserMessage(\"Can you tell me a joke?\"),\n",
    "        AssistantMessage(\"Sure, here is a joke for you: Why don't scientists trust atoms? Because they make up everything!\"),\n",
    "        UserMessage(\"That's funny. Can you tell me another one?\"),\n",
    "    ],\n",
    "    configs={\n",
    "        \"max_tokens\": 5\n",
    "    }\n",
    ")\n",
    "chat_completion_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:03:41.911247Z",
     "start_time": "2023-11-30T11:03:40.969583Z"
    }
   },
   "id": "f7c1b8be2579d9e0"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_completion_result = object='ChatCompletion' finish_reason=<ChatCompletionFinishReason.function_calls: 'function_call'> message=ChatCompletionAssistantMessage(content=None, role=<ChatCompletionRole.assistant: 'assistant'>, function_call=ChatCompletionFunctionCall(arguments={'a': 112, 'b': 22}, name='plus_a_and_b')) created_timestamp=1701342223979\n",
      "function name: plus_a_and_b, argument content: {\"a\": 112, \"b\": 22}\n"
     ]
    }
   ],
   "source": [
    "# function call\n",
    "function = Function(\n",
    "    name=\"plus_a_and_b\",\n",
    "    description=\"Sum up a and b and return the result\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The first number\"\n",
    "            },\n",
    "            \"b\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The second number\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"]\n",
    "    },\n",
    ")\n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a professional assistant.\"),\n",
    "        UserMessage(\"What is the result of 112 plus 22?\"),\n",
    "    ],\n",
    "    functions=[function]\n",
    ")\n",
    "print(f\"chat_completion_result = {chat_completion_result}\")\n",
    "\n",
    "assistant_function_call_message = chat_completion_result.message\n",
    "fucntion_name = assistant_function_call_message.function_call.name\n",
    "argument_content = json.dumps(assistant_function_call_message.function_call.arguments)\n",
    "print(f\"function name: {fucntion_name}, argument content: {argument_content}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:03:44.068090Z",
     "start_time": "2023-11-30T11:03:42.646835Z"
    }
   },
   "id": "2645bdc3df011e7d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ed6957f0c380ba9f"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "ChatCompletion(object='ChatCompletion', finish_reason=<ChatCompletionFinishReason.stop: 'stop'>, message=ChatCompletionAssistantMessage(content='The result of 112 plus 22 is 134.', role=<ChatCompletionRole.assistant: 'assistant'>, function_call=None), created_timestamp=1701342226882)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add function message\n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a professional assistant.\"),\n",
    "        UserMessage(\"What is the result of 112 plus 22?\"),\n",
    "        assistant_function_call_message,\n",
    "        FunctionMessage(name=fucntion_name, content=\"144\")\n",
    "    ],\n",
    "    functions=[function]\n",
    ")\n",
    "chat_completion_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:03:46.969143Z",
     "start_time": "2023-11-30T11:03:46.043885Z"
    }
   },
   "id": "9df9a8b9eafa17d9"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 \n",
      "11 12 13 14 15 16 17 18 19 20 \n",
      "21 22 23 24 25 26 27 28 29 30 \n",
      "31 32 33 34 35 36 37 38 39 40 \n",
      "41 42 43 44 45 46 47 48 49 50 \n",
      "51 52 53 54 55 56 57 58 59 60 \n",
      "61 62 63 64 65 66 67 68 69 70 \n",
      "71 72 73 74 75 76 77 78 79 80 \n",
      "81 82 83 84 85 86 87 88 89 90 \n",
      "91 92 93 94 95 96 97 98 99 100\n",
      " message object: content='1 2 3 4 5 6 7 8 9 10 \\n11 12 13 14 15 16 17 18 19 20 \\n21 22 23 24 25 26 27 28 29 30 \\n31 32 33 34 35 36 37 38 39 40 \\n41 42 43 44 45 46 47 48 49 50 \\n51 52 53 54 55 56 57 58 59 60 \\n61 62 63 64 65 66 67 68 69 70 \\n71 72 73 74 75 76 77 78 79 80 \\n81 82 83 84 85 86 87 88 89 90 \\n91 92 93 94 95 96 97 98 99 100' role=<ChatCompletionRole.assistant: 'assistant'> function_call=None\n"
     ]
    }
   ],
   "source": [
    "# generate in stream mode\n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        UserMessage(\"Please count from 1 to 100, and add a new line after every 10 numbers.\"),\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "for item in chat_completion_result:\n",
    "    \n",
    "    if item.get(\"object\") == \"ChatCompletionChunk\":\n",
    "        chunk = ChatCompletionChunk(**item)\n",
    "        print(chunk.delta, end=\"\", flush=True)\n",
    "        \n",
    "    elif item.get(\"object\") == \"ChatCompletion\":\n",
    "        result = ChatCompletion(**item)\n",
    "        print(f\"\\n message object: {result.message}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T11:08:05.624547Z",
     "start_time": "2023-11-30T11:07:58.499361Z"
    }
   },
   "id": "4f3290f87635152a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dab2cb3f84463700"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

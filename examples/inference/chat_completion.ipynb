{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import taskingai\n",
    "# Load TaskingAI API Key from environment variable"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a6bfd1682fcb23f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TaskingAI Model Inference: Chat Completion"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "657463bd357a3c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from taskingai.inference import *\n",
    "import json\n",
    "# choose an available chat_completion model from your project\n",
    "model_id = \"YOUR_MODEL_ID\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49abde692940b09e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# normal \n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a professional assistant.\"),\n",
    "        UserMessage(\"Hi\"),\n",
    "    ]\n",
    ")\n",
    "chat_completion_result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43dcc632665f0de4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# multi round chat completion\n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a professional assistant.\"),\n",
    "        UserMessage(\"Hi\"),\n",
    "        AssistantMessage(\"Hello! How can I assist you today?\"),\n",
    "        UserMessage(\"Can you tell me a joke?\"),\n",
    "        AssistantMessage(\"Sure, here is a joke for you: Why don't scientists trust atoms? Because they make up everything!\"),\n",
    "        UserMessage(\"That's funny. Can you tell me another one?\"),\n",
    "    ]\n",
    ")\n",
    "chat_completion_result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8933bc07f4b3228"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# config max tokens\n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a professional assistant.\"),\n",
    "        UserMessage(\"Hi\"),\n",
    "        AssistantMessage(\"Hello! How can I assist you today?\"),\n",
    "        UserMessage(\"Can you tell me a joke?\"),\n",
    "        AssistantMessage(\"Sure, here is a joke for you: Why don't scientists trust atoms? Because they make up everything!\"),\n",
    "        UserMessage(\"That's funny. Can you tell me another one?\"),\n",
    "    ],\n",
    "    configs={\n",
    "        \"max_tokens\": 5\n",
    "    }\n",
    ")\n",
    "chat_completion_result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7c1b8be2579d9e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# function call\n",
    "function = Function(\n",
    "    name=\"plus_a_and_b\",\n",
    "    description=\"Sum up a and b and return the result\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"a\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The first number\"\n",
    "            },\n",
    "            \"b\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The second number\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"a\", \"b\"]\n",
    "    },\n",
    ")\n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a professional assistant.\"),\n",
    "        UserMessage(\"What is the result of 112 plus 22?\"),\n",
    "    ],\n",
    "    functions=[function]\n",
    ")\n",
    "print(f\"chat_completion_result = {chat_completion_result}\")\n",
    "\n",
    "assistant_function_call_message = chat_completion_result.message\n",
    "fucntion_name = assistant_function_call_message.function_call.name\n",
    "argument_content = json.dumps(assistant_function_call_message.function_call.arguments)\n",
    "print(f\"function name: {fucntion_name}, argument content: {argument_content}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2645bdc3df011e7d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ed6957f0c380ba9f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# add function message\n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a professional assistant.\"),\n",
    "        UserMessage(\"What is the result of 112 plus 22?\"),\n",
    "        assistant_function_call_message,\n",
    "        FunctionMessage(name=fucntion_name, content=\"144\")\n",
    "    ],\n",
    "    functions=[function]\n",
    ")\n",
    "chat_completion_result"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9df9a8b9eafa17d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate in stream mode\n",
    "chat_completion_result = taskingai.inference.chat_completion(\n",
    "    model_id=model_id,\n",
    "    messages=[\n",
    "        UserMessage(\"Please count from 1 to 100, and add a new line after every 10 numbers.\"),\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "for item in chat_completion_result:\n",
    "    \n",
    "    if isinstance(item, ChatCompletionChunk):\n",
    "        print(item.delta, end=\"\", flush=True)\n",
    "        \n",
    "    elif isinstance(item, ChatCompletion):\n",
    "        print(f\"\\nFinished with reason: {item.finish_reason}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f3290f87635152a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
